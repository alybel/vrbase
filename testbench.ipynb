{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "{'anomalydetection': 7, 'overview': 5, 'randomforest': 12, 'infographic': 5, 'businessanalytics': 12, 'creditcard': 7, 'predictiveanalytics': 12, 'visualization': 7, 'fintech': 7, 'machinelearning': 12, 'transform': 5, 'onlinepayment': 12, 'finance': 5, 'datamining': 7, 'businessstrategy': 5, 'python': 5, 'outlierdetection': 7, 'scikit': 12, 'sqlperformance': 7, 'unsupervisedlearning': 12, 'prescriptiveanalytics': 12, 'summary': 5, 'dataflow': 5, 'deeplearning': 12, 'avoidoverfitting': 7, 'team': 7, 'analytics': 7, 'trading': 5, 'statistic': 5, 'churn': 12, 'technology': 5, 'datascientist': 12, 'e-commerce': 7, 'saas': 12, 'dataanalytics': 12, 'research': 5, 'innovation': 5, 'artificialintelligence': 12, 'bayes': 12, 'neuralnetwork': 12, 'multivariatecorrelation': 7, 'internetofthings': 7, 'credit': 5, 'supervisedlearning': 12, 'datascience': 12}\n",
      "{'shop': 1000, 'google': 1000, 'veristorm': 1000, 'cheap': 1000, 'webinar': 1000, 'hiring': 1000, 'francisco': 1000, 'sas': 1000, 'apply': 1000, 'sap': 1000, 'seminar': 1000, 'guarantee': 1000, 'big data': 1000, 'bigdata': 1000, 'application': 1000, 'only': 1000, 'music': 1000, 'pivotal': 1000, 'local': 1000, 'buy': 1000, 'jobs': 1000, 'offer': 1000, 'marketing': 1000, 'price': 1000, 'free': 1000, 'discount': 1000, 'job': 1000, 'birthday': 1000, 'oracle': 1000, 'opportunity': 1000, 'rapidminer': 1000, 'hire': 1000, 'knime': 1000, 'ibm': 1000, 'emc': 1000, 'dato': 1000, 'ebay': 1000, 'advertising': 1000, 'azure': 1000, 'position': 1000, 'microsoft': 1000, 'spss': 1000}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "account = \"AlexanderD_Beck\"\n",
    "import sys\n",
    "sys.path.append(\"bluebird/\")\n",
    "sys.path.append(\"accounts/%s/\"%account)\n",
    "import config as cfg\n",
    "import bblib as bbl\n",
    "import bbanalytics as bba\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "bbl.set_cfg(cfg)\n",
    "bba.set_cfg(cfg)\n",
    "bba.initialize()\n",
    "bbl.tweepy.__version__\n",
    "#TextBuilder = bbl.BuildText(preambles=cfg.preambles, hashtags=cfg.hashtags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Check Score of Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = 'Churn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "Churn Review\n",
      "['churn', 'review']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bba.score_tweets(t = t, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 0)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBuilder.build_text(url = 'http://shmental.com/finance-minister-arun-jaitley-calls-for-prudent-expenditure-management/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "auth, api = bblib.connect_app_to_twitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tl = api.user_timeline(screen_name = account, count = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3600"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "User = bblib.get_info_from_account_id(api, 'valureach')\n",
    "User.followers_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "561471163785023489"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl[-1].id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tl2 = api.user_timeline(screen_name = account, count = 200, max_id =561471163785023489 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tl2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tweepy.models.Status at 0x104d312d0>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api.retweets_of_me()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "me = api.me()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "318"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "me.statuses_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Debug Build Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = \"https://t.co/U188rP6tdB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "html = BT.get_ws_html(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BT = bbl.BuildText([], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('datascience', 12), ('visualization', 7), ('analytics', 7), ('finance', 5), ('python', 5), ('transform', 5), ('research', 5), ('statistic', 5), ('technology', 5)]\n"
     ]
    }
   ],
   "source": [
    "text, score = BT.build_text(url, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Python for Data Science vs Python for Web Development - Data Science Central https://t.co/U188rP6tdB #datascience #visualization #analytics',\n",
       " 99)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('pickle.sav', 'w') as f: \n",
    "    pickle.dump(html, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import UnicodeDammit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "UnicodeDammit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BT.build_text(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lxml.etree._ElementTree at 0x1080d1320>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<lxml.etree._ElementTree object at 0x1080d1320>\n"
     ]
    }
   ],
   "source": [
    "print ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lxml import etree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html id=\"blaskan\" class=\"no-js\" lang=\"en-US\" prefix=\"og: http://ogp.me/ns#\"><!--<![endif]-->\n",
      "<head>\n",
      "\t<meta charset=\"UTF-8\">\n",
      "\t<title>26 Things I Learned in the Deep Learning Summer School - Marek Rei</title>\n",
      "\t\n",
      "\t\t<style type=\"text/css\">\n",
      "\t\t/**\n",
      "\t\t * Bulletproof syntax:\n",
      "\t\t * http://www.fontspring.com/blog/further-hardening-of-the-bulletproof-syntax\n",
      "\t\t * Font files generated by Font Squirrel:\n",
      "\t\t * http://www.fontsquirrel.com\n",
      "\t\t * License: Open Font License. See http://www.marekrei.com/blog/wp-content/themes/blaskan/OFL.txt.\n",
      "\t\t */\n",
      "\t\t@font-face {\n",
      "\t\t\tfont-family: 'LeagueGothic';\n",
      "\t\t\tsrc: url('http://www.marekrei.com/blog/wp-content/themes/blaskan/fonts/league_gothic-webfont.eot'); /* IE9 Compat Modes */\n",
      "\t\t\tsrc: url('http://www.marekrei.com/blog/wp-content/themes/blaskan/fonts/league_gothic-webfont.eot?iefix') format('eot'), /* IE6-IE8 */\n",
      "\t\t\t     url('http://www.marekrei.com/blog/wp-content/themes/blaskan/fonts/league_gothic-webfont.woff') format('woff'), /* Modern Browsers */\n",
      "\t\t\t     url('http://www.marekrei.com/blog/wp-content/themes/blaskan/fonts/league_gothic-webfont.ttf')  format('truetype'), /* Safari, Android, iOS */\n",
      "\t\t\t     url('http://www.marekrei.com/blog/wp-content/themes/blaskan/fonts/league_gothic-webfont.svg#webfont3nLbXkSC') format('svg'); /* Legacy iOS */\n",
      "\t\t}\n",
      "\t\t</style>\n",
      "\t\t\n",
      "<!-- This site is optimized with the Yoast SEO plugin v2.3.4 - https://yoast.com/wordpress/plugins/seo/ -->\n",
      "<meta name=\"description\" content=\"Here is a list of small interesting nuggets of information from the summer school, regarding neural networks and deep learning.\">\n",
      "<link rel=\"canonical\" href=\"http://www.marekrei.com/blog/26-things-i-learned-in-the-deep-learning-summer-school/\">\n",
      "<meta property=\"og:locale\" content=\"en_US\">\n",
      "<meta property=\"og:type\" content=\"article\">\n",
      "<meta property=\"og:title\" content=\"26 Things I Learned in the Deep Learning Summer School - Marek Rei\">\n",
      "<meta property=\"og:description\" content=\"Here is a list of small interesting nuggets of information from the summer school, regarding neural networks and deep learning.\">\n",
      "<meta property=\"og:url\" content=\"http://www.marekrei.com/blog/26-things-i-learned-in-the-deep-learning-summer-school/\">\n",
      "<meta property=\"og:site_name\" content=\"Marek Rei\">\n",
      "<meta property=\"article:section\" content=\"Uncategorized\">\n",
      "<meta property=\"article:published_time\" content=\"2015-08-19T22:07:22+00:00\">\n",
      "<meta property=\"article:modified_time\" content=\"2015-09-18T17:19:04+00:00\">\n",
      "<meta property=\"og:updated_time\" content=\"2015-09-18T17:19:04+00:00\">\n",
      "<meta property=\"og:image\" content=\"http://www.marekrei.com/blog/wp-content/uploads/2015/08/dlss-3aug2015.png\">\n",
      "<meta property=\"og:image\" content=\"http://www.marekrei.com/blog/wp-content/uploads/2015/08/dlss-3aug20152.png\">\n",
      "<meta property=\"og:image\" content=\"http://www.marekrei.com/blog/wp-content/uploads/2015/08/bottou1.png\">\n",
      "<meta property=\"og:image\" content=\"http://www.marekrei.com/blog/wp-content/uploads/2015/08/bottou2.png\">\n",
      "<meta property=\"og:image\" content=\"http://www.marekrei.com/blog/wp-content/uploads/2015/08/gwtaylor_cvpr2010.png\">\n",
      "<meta property=\"og:image\" content=\"http://www.marekrei.com/blog/wp-content/uploads/2015/08/14439811.png\">\n",
      "<meta property=\"og:image\" content=\"http://www.marekrei.com/blog/wp-content/uploads/2015/08/talk_Montreal_part2_pdf.png\">\n",
      "<meta property=\"og:image\" content=\"http://www.marekrei.com/blog/wp-content/uploads/2015/08/dlss_systems_1-300x209.png\">\n",
      "<meta property=\"og:image\" content=\"http://www.marekrei.com/blog/wp-content/uploads/2015/08/dlss_systems_2.png\">\n",
      "<meta property=\"og:image\" content=\"http://www.marekrei.com/blog/wp-content/uploads/2015/08/dlss_systems_3.png\">\n",
      "<meta property=\"og:image\" content=\"http://www.marekrei.com/blog/wp-content/uploads/2015/08/fish.jpeg\">\n",
      "<meta property=\"og:image\" content=\"http://www.marekrei.com/blog/wp-content/uploads/2015/08/goodfellow_adv.png\">\n",
      "<meta property=\"og:image\" content=\"http://www.marekrei.com/blog/wp-content/uploads/2015/08/blunsom-lm-mt2-270x300.png\">\n",
      "<meta property=\"og:image\" content=\"http://www.marekrei.com/blog/wp-content/uploads/2015/08/blunsom-lm-mt.png\">\n",
      "<meta property=\"og:image\" content=\"http://www.marekrei.com/blog/wp-content/uploads/2015/08/edison_vs_einstein.png\">\n",
      "<meta property=\"og:image\" content=\"http://www.marekrei.com/blog/wp-content/uploads/2015/08/2015_DLSS_ConvexOptimization-300x233.png\">\n",
      "<meta property=\"og:image\" content=\"http://www.marekrei.com/blog/wp-content/uploads/2015/08/denton_generating_images.png\">\n",
      "<!-- / Yoast SEO plugin. -->\n",
      "\n",
      "<link rel=\"alternate\" type=\"application/rss+xml\" title=\"Marek Rei &#187; Feed\" href=\"http://www.marekrei.com/blog/feed/\">\n",
      "<link rel=\"alternate\" type=\"application/rss+xml\" title=\"Marek Rei &#187; Comments Feed\" href=\"http://www.marekrei.com/blog/comments/feed/\">\n",
      "<link rel=\"alternate\" type=\"application/rss+xml\" title=\"Marek Rei &#187; 26 Things I Learned in the Deep Learning Summer School Comments Feed\" href=\"http://www.marekrei.com/blog/26-things-i-learned-in-the-deep-learning-summer-school/feed/\">\n",
      "\t\t<script type=\"text/javascript\">\n",
      "\t\t\twindow._wpemojiSettings = {\"baseUrl\":\"http:\\/\\/s.w.org\\/images\\/core\\/emoji\\/72x72\\/\",\"ext\":\".png\",\"source\":{\"concatemoji\":\"http:\\/\\/www.marekrei.com\\/blog\\/wp-includes\\/js\\/wp-emoji-release.min.js?ver=4.3.1\"}};\n",
      "\t\t\t!function(a,b,c){function d(a){var c=b.createElement(\"canvas\"),d=c.getContext&&c.getContext(\"2d\");return d&&d.fillText?(d.textBaseline=\"top\",d.font=\"600 32px Arial\",\"flag\"===a?(d.fillText(String.fromCharCode(55356,56812,55356,56807),0,0),c.toDataURL().length>3e3):(d.fillText(String.fromCharCode(55357,56835),0,0),0!==d.getImageData(16,16,1,1).data[0])):!1}function e(a){var c=b.createElement(\"script\");c.src=a,c.type=\"text/javascript\",b.getElementsByTagName(\"head\")[0].appendChild(c)}var f,g;c.supports={simple:d(\"simple\"),flag:d(\"flag\")},c.DOMReady=!1,c.readyCallback=function(){c.DOMReady=!0},c.supports.simple&&c.supports.flag||(g=function(){c.readyCallback()},b.addEventListener?(b.addEventListener(\"DOMContentLoaded\",g,!1),a.addEventListener(\"load\",g,!1)):(a.attachEvent(\"onload\",g),b.attachEvent(\"onreadystatechange\",function(){\"complete\"===b.readyState&&c.readyCallback()})),f=c.source||{},f.concatemoji?e(f.concatemoji):f.wpemoji&&f.twemoji&&(e(f.twemoji),e(f.wpemoji)))}(window,document,window._wpemojiSettings);\n",
      "\t\t</script>\n",
      "\t\t<style type=\"text/css\">\n",
      "img.wp-smiley,\n",
      "img.emoji {\n",
      "\tdisplay: inline !important;\n",
      "\tborder: none !important;\n",
      "\tbox-shadow: none !important;\n",
      "\theight: 1em !important;\n",
      "\twidth: 1em !important;\n",
      "\tmargin: 0 .07em !important;\n",
      "\tvertical-align: -0.1em !important;\n",
      "\tbackground: none !important;\n",
      "\tpadding: 0 !important;\n",
      "}\n",
      "</style>\n",
      "<link rel=\"stylesheet\" id=\"blaskan-framework-css\" href=\"http://www.marekrei.com/blog/wp-content/themes/blaskan/framework.css?ver=4.3.1\" type=\"text/css\" media=\"screen\">\n",
      "<link rel=\"stylesheet\" id=\"blaskan-style-css\" href=\"http://www.marekrei.com/blog/wp-content/themes/blaskan-child/style.css?ver=4.3.1\" type=\"text/css\" media=\"all\">\n",
      "<link rel=\"stylesheet\" id=\"parent-style-css\" href=\"http://www.marekrei.com/blog/wp-content/themes/blaskan/style.css?ver=4.3.1\" type=\"text/css\" media=\"all\">\n",
      "<link rel=\"stylesheet\" id=\"easy_table_style-css\" href=\"http://www.marekrei.com/blog/wp-content/plugins/easy-table/themes/default/style.css?ver=1.5.3\" type=\"text/css\" media=\"all\">\n",
      "<link rel=\"stylesheet\" id=\"rjqc-jqplot-css\" href=\"http://www.marekrei.com/blog/wp-content/plugins/rj-quickcharts/css/jquery.jqplot.min.css?ver=4.3.1\" type=\"text/css\" media=\"all\">\n",
      "<script type=\"text/javascript\" src=\"http://www.marekrei.com/blog/wp-content/themes/blaskan/js/libs/modernizr.min.js?ver=4.3.1\"></script>\n",
      "<script type=\"text/javascript\" src=\"http://www.marekrei.com/blog/wp-includes/js/jquery/jquery.js?ver=1.11.3\"></script>\n",
      "<script type=\"text/javascript\" src=\"http://www.marekrei.com/blog/wp-includes/js/jquery/jquery-migrate.min.js?ver=1.2.1\"></script>\n",
      "<script type=\"text/javascript\" src=\"http://www.marekrei.com/blog/wp-content/themes/blaskan/js/libs/jquery.fitvids.js?ver=4.3.1\"></script>\n",
      "<script type=\"text/javascript\" src=\"http://www.marekrei.com/blog/wp-content/themes/blaskan/js/mylibs/helper.js?ver=4.3.1\"></script>\n",
      "<script type=\"text/javascript\">\n",
      "/* <![CDATA[ */\n",
      "var objectL10n = {\"blaskan_navigation_title\":\"- Navigation -\"};\n",
      "/* ]]> */\n",
      "</script>\n",
      "<script type=\"text/javascript\" src=\"http://www.marekrei.com/blog/wp-content/themes/blaskan/js/script.js?ver=4.3.1\"></script>\n",
      "<script type=\"text/javascript\" src=\"http://www.marekrei.com/blog/wp-content/plugins/rj-quickcharts/js/min/rjqc-frontend-full.min.js?ver=4.3.1\"></script>\n",
      "<script type=\"text/javascript\" src=\"http://www.marekrei.com/blog/wp-content/plugins/google-analyticator/external-tracking.min.js?ver=6.4.9\"></script>\n",
      "<link rel=\"shortlink\" href=\"http://www.marekrei.com/blog/?p=333\">\n",
      "<meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\">\r",
      "<meta name=\"viewport\" content=\"width=device-width\">\r",
      "<link rel=\"pingback\" href=\"http://www.marekrei.com/blog/xmlrpc.php\">\r",
      "<style type=\"text/css\" id=\"syntaxhighlighteranchor\"></style>\n",
      "<!-- Google Analytics Tracking by Google Analyticator 6.4.9: http://www.videousermanuals.com/google-analyticator/ -->\n",
      "<script type=\"text/javascript\">\n",
      "    var analyticsFileTypes = [''];\n",
      "    var analyticsSnippet = 'disabled';\n",
      "    var analyticsEventTracking = 'enabled';\n",
      "</script>\n",
      "<script type=\"text/javascript\">\n",
      "\t(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n",
      "\t(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n",
      "\tm=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n",
      "\t})(window,document,'script','//www.google-analytics.com/analytics.js','ga');\n",
      "\tga('create', 'UA-5753540-5', 'auto');\n",
      " \n",
      "\tga('send', 'pageview');\n",
      "</script>\n",
      "\t</head>\n",
      "<body class=\"single single-post postid-333 single-format-standard simple-menu sidebar\">\n",
      "<div id=\"site\">\n",
      "\t<div id=\"wrapper\">\n",
      "\t\t<header id=\"header\" role=\"banner\">\n",
      "\t\t  <div id=\"site-name\"><a href=\"http://www.marekrei.com/blog/\" title=\"Marek Rei\" rel=\"home\">Marek Rei</a></div><div id=\"header-message\">Thoughts on Machine Learning and Natural Language Processing</div><nav id=\"nav\" role=\"navigation\"><div class=\"menu\"><ul><li class=\"page_item page-item-2\"><a href=\"http://www.marekrei.com/blog/about-me/\">About Me</a></li></ul></div>\n",
      "</nav>\t\t</header>\n",
      "\t\t<!-- / #header -->\n",
      "\n",
      "\t\t\n",
      "\t\t<section id=\"content\" role=\"main\">\n",
      "\t\t\t\n",
      "\n",
      "\t\n",
      "\t\t\t\n",
      "\t\t<article id=\"post-333\" class=\"post-333 post type-post status-publish format-standard hentry category-uncategorized\">\n",
      "\t\t\t<header>\n",
      "\t\t\t\t\t\t\t\t\n",
      "\t\t\t  \t\t\t\t  <time datetime=\"2015-08-19T22:07:22+00:00\" pubdate>August 19, 2015</time>\n",
      "\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t<h1>26 Things I Learned in the Deep Learning Summer School</h1>\n",
      "\t\t\t\t\t\t\t</header>\n",
      "\t\t\n",
      "\t\t\t<div class=\"content\">\n",
      "\t\t\t\t<p>In the beginning of August I got the chance to attend the Deep Learning Summer School in Montreal. It consisted of 10 days of talks from some of the most well-known&#160;neural network researchers. During this time I learned a lot, way more&#160;than I could ever fit into a blog post. Instead of trying to pass on 60 hours worth of neural network knowledge, I&#160;have made a list of small interesting nuggets of information that I was able to summarise in a paragraph.</p>\n",
      "<p>At the moment of writing, the <a href=\"https://sites.google.com/site/deeplearningsummerschool/schedule\">summer school website</a> is still online, along with all the presentation slides. All of the information and most of the illustrations come from these slides and are the work of their&#160;original authors.&#160;The talks in the summer school were filmed as well, hopefully they will also find their way to the web.</p>\n",
      "<p><strong>Update</strong>: <a href=\"http://videolectures.net/deeplearning2015_montreal/\">the Deep Learning Summer School videos are now online</a>.</p>\n",
      "<p>Alright, let&#8217;s get started.</p>\n",
      "<h2>1. The need for distributed representations</h2>\n",
      "<p>During his first talk, Yoshua Bengio said &#8220;This is my most important slide&#8221;. You can see that slide below:<a href=\"http://www.marekrei.com/blog/wp-content/uploads/2015/08/dlss-3aug2015.png\"><img class=\"alignnone size-full wp-image-334\" src=\"http://www.marekrei.com/blog/wp-content/uploads/2015/08/dlss-3aug2015.png\" alt=\"dlss-3aug2015\" width=\"1100\" height=\"850\"></a></p>\n",
      "<p>Let&#8217;s say you have a classifier that needs to detect people that are male/female, have glasses or&#160;don&#8217;t have glasses, and are tall/short. With non-distributed representations, you are dealing with 2*2*2=8 different classes of people. In order to train an accurate classifier, you need to have enough training data for each of these 8 classes. However, with distributed representations, each of these properties could be captured by a different dimension. This means that even if your classifier has never encountered tall men with glasses, it would be able to detect them, because it has learned to detect gender, glasses and height independently from all the other examples.</p>\n",
      "<h2>2. Local minima are not a problem in high dimensions</h2>\n",
      "<p>The team of Yoshua Bengio have experimentally found that when optimising the parameters of high-dimensional neural nets, there effectively are no local minima. Instead, there are saddle points which are local minima in some dimensions but not all. This means that training can slow down quite a lot in these points, until the network figures out how to escape, but as long as we&#8217;re willing to wait long enough then it will find a way.</p>\n",
      "<p>Below is a graph demonstrating a network during training, oscillating between two states: approaching a saddle point and then escaping it.</p>\n",
      "<p><a href=\"http://www.marekrei.com/blog/wp-content/uploads/2015/08/dlss-3aug20152.png\"><img class=\"alignnone size-full wp-image-340\" src=\"http://www.marekrei.com/blog/wp-content/uploads/2015/08/dlss-3aug20152.png\" alt=\"dlss-3aug20152\" width=\"867\" height=\"461\"></a></p>\n",
      "<p>Given one specific dimension, there is some small probability \\(p\\) with which a point is a local minimum, but not a global minimum, in that dimension. Now, the probability of a point in a 1000-dimensional space being an incorrect local minimum in <strong>all</strong> of these would be \\(p^{1000}\\), which is just astronomically small. However, the probability of it being a local minimum in <strong>some</strong> of these dimensions is actually quite high. And when we get these minima in many dimensions at once, then training can appear to be stuck until it finds the right direction.</p>\n",
      "<p>In addition, this probability \\(p\\) will increase as the loss function&#160;gets closer to the global minimum. &#160;This means that if we do ever end up at a genuine local minimum, then for all intents and purposes it will be close enough to the global minimum that it will not matter.</p>\n",
      "<h2>3. Derivatives derivatives derivatives</h2>\n",
      "<p>Leon Bottou had some useful tables with activation functions, loss functions, and their corresponding derivatives. I&#8217;ll keep these here for later.</p>\n",
      "<p><a href=\"http://www.marekrei.com/blog/wp-content/uploads/2015/08/bottou1.png\"><img class=\"alignnone size-full wp-image-337\" src=\"http://www.marekrei.com/blog/wp-content/uploads/2015/08/bottou1.png\" alt=\"bottou1\" width=\"838\" height=\"349\"></a></p>\n",
      "<p><a href=\"http://www.marekrei.com/blog/wp-content/uploads/2015/08/bottou2.png\"><img class=\"alignnone size-full wp-image-338\" src=\"http://www.marekrei.com/blog/wp-content/uploads/2015/08/bottou2.png\" alt=\"bottou2\" width=\"870\" height=\"332\"></a></p>\n",
      "<p>&#160;</p>\n",
      "<p><strong>Update</strong>: As pointed out by commenters, the min and max functions in the ramp formula should be switched.</p>\n",
      "<h2>4. Weight initialisation strategy</h2>\n",
      "<p>The current recommended strategy for initialising weights in a neural network is to sample values \\(W_{i,j}^{(k)}\\)&#160;uniformly from \\([-b,b]\\), where</p>\n",
      "<p style=\"text-align: center;\">\\(b = \\sqrt{\\frac{6}{H_k + H_{k+1}}}\\)</p>\n",
      "<p>\\(H_k\\) and \\(H_{k+1}\\) are the sizes of hidden layers before and after the weight matrix.</p>\n",
      "<p>Recommended by&#160;Hugo Larochelle, published by&#160;Glorot &amp; Bengio&#160;(2010).</p>\n",
      "<h2>5. Neural net training tricks</h2>\n",
      "<p>A few practical suggestions from&#160;Hugo Larochelle:</p>\n",
      "<ul>\n",
      "<li>Normalise real-valued data. Subtract the mean and divide by standard deviation.</li>\n",
      "<li>Decrease the learning rate during training.</li>\n",
      "<li>Can update using mini-batches &#8211; the gradient is more stable.</li>\n",
      "<li>Can use momentum, to get through plateaus.</li>\n",
      "</ul>\n",
      "<h2>6. Gradient checking</h2>\n",
      "<p>If you implemented your backprop by hand and it&#8217;s not working, then there&#8217;s roughly 99% chance&#160;that the gradient&#160;calculation has&#160;a bug. Use gradient checking to identify the issue. The idea is to use the definition of a gradient: how much will the model error change, if we increase a specific weight by a small amount.</p>\n",
      "<p style=\"text-align: center;\">\\(\\frac{\\partial f(x)}{\\partial x} \\approx&#160;\\frac{f(x+\\epsilon) &#8211; f(x-\\epsilon)}{2\\epsilon}\\)</p>\n",
      "<p>A more in-depth explanation is available here: <a href=\"http://ufldl.stanford.edu/wiki/index.php/Gradient_checking_and_advanced_optimization\">Gradient checking and advanced optimization</a></p>\n",
      "<h2>7. Motion tracking</h2>\n",
      "<p>Human motion tracking can be done with impressive accuracy. Below are examples from the paper&#160;<a href=\"http://www.uoguelph.ca/~gwtaylor/publications/cvpr2010/gwtaylor_cvpr2010.pdf\">Dynamical Binary Latent Variable Models for 3D Human Pose Tracking</a> by Graham Taylor et al. (2010). The method uses&#160;conditional restricted&#160;Boltzmann machines.</p>\n",
      "<p><a href=\"http://www.marekrei.com/blog/wp-content/uploads/2015/08/gwtaylor_cvpr2010.png\"><img class=\"alignnone size-full wp-image-356\" src=\"http://www.marekrei.com/blog/wp-content/uploads/2015/08/gwtaylor_cvpr2010.png\" alt=\"gwtaylor_cvpr2010\" width=\"811\" height=\"359\"></a></p>\n",
      "<h2>8. Syntax or no syntax? (aka, &#8220;is syntax a thing?&#8221;)</h2>\n",
      "<p>Chris Manning and&#160;Richard Socher have put a lot of effort into developing compositional models that combine neural embeddings with more traditional parsing&#160;approaches. This culminated with a&#160;<a href=\"http://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf\">Recursive Neural Tensor Network</a>&#160;(Socher et al., 2013), which uses both additive and multiplicative interactions to combine word meanings along a parse tree.</p>\n",
      "<p>And then, the model was beaten (by quite a margin) by the&#160;<a href=\"http://arxiv.org/abs/1405.4053\">Paragraph Vector</a> (Le &amp; Mikolov, 2014), which knows absolutely nothing about the sentence structure or syntax. Chris Manning referred to this result as &#8220;a defeat for creating &#8216;good&#8217; compositional vectors&#8221;.</p>\n",
      "<p>However, more recent work using parse trees has again surpassed this result.&#160;<a href=\"http://www.cs.cornell.edu/~oirsoy/files/nips14drsv.pdf\">Irsoy &amp; Cardie (NIPS, 2014)</a> managed to beat paragraph vectors by going &#8220;deep&#8221; with their networks in multiple dimensions. Finally, <a href=\"https://aclweb.org/anthology/P/P15/P15-1150.pdf\">Tai et al. (ACL, 2015)</a> have improved the results again by combining LSTMs with parse trees.</p>\n",
      "<p>The accuracies&#160;of these models on the Stanford 5-class sentiment dataset are as follows:</p>\n",
      "<div class=\"table-responsive\"><table style=\"width:500px; \" class=\"easy-table easy-table-default \" border=\"0\">\n",
      "<thead>\r\n",
      "<tr><th style=\"width:100px;text-align:left\">Method</th>\n",
      "<th style=\"width:50px;text-align:center\"> Accuracy</th>\n",
      "</tr>\n",
      "</thead>\n",
      "<tbody>\r\n",
      "<tr><td style=\"text-align:left\">RNTN (Socher et al. 2013)</td>\n",
      "<td style=\"text-align:center\"> 45.7</td>\n",
      "</tr>\n",
      "\r\n",
      "<tr><td style=\"text-align:left\">Paragraph Vector (Le &amp; Mikolov 2014)</td>\n",
      "<td style=\"text-align:center\">&#160;48.7</td>\n",
      "</tr>\n",
      "\r\n",
      "<tr><td style=\"text-align:left\">DRNN (Irsoy &amp; Cardie 2014)</td>\n",
      "<td style=\"text-align:center\"> 49.8</td>\n",
      "</tr>\n",
      "\r\n",
      "<tr><td style=\"text-align:left\">Tree LSTM (Tai et al. 2015)</td>\n",
      "<td style=\"text-align:center\"> 50.9</td>\n",
      "</tr>\n",
      "</tbody></table></div>\n",
      "<p>So it seems that, at the moment, models using the parse tree are beating simpler approaches. I&#8217;m curious to see if and when the next syntax-free approach&#160;will emerge that will advance this race. After all, the goal of many neural models is not to discard the underlying grammar, but to implicitly capture it in the same network.</p>\n",
      "<h2>9. Distributed vs distributional</h2>\n",
      "<p>Chris Manning himself cleared up the confusion between the two words.</p>\n",
      "<p><strong>Distributed</strong>: A concept is represented as continuous activation levels in a number of elements. Like a dense word embedding, as opposed to 1-hot vectors.</p>\n",
      "<p><strong>Distributional</strong>:&#160;Meaning is represented by contexts of use. Word2vec is distributional, but so are count-based word vectors, as we use the contexts of the word to model the meaning.</p>\n",
      "<h2>10. The state of dependency parsing</h2>\n",
      "<p>Comparison of dependency parsers on the Penn Treebank:</p>\n",
      "<div class=\"table-responsive\"><table style=\"width:100%; \" class=\"easy-table easy-table-default \" border=\"0\">\n",
      "<thead>\r\n",
      "<tr><th style=\"text-align:left\">Parser</th>\n",
      "<th style=\"text-align:center\">&#160;Unlabelled Accuracy</th>\n",
      "<th style=\"text-align:center\"> Labelled Acccuracy</th>\n",
      "<th>&#160;Speed (sent/s)</th>\n",
      "</tr>\n",
      "</thead>\n",
      "<tbody>\r\n",
      "<tr><td style=\"text-align:left\">MaltParser</td>\n",
      "<td style=\"text-align:center\"> 89.8</td>\n",
      "<td style=\"text-align:center\"> 87.2</td>\n",
      "<td> 469</td>\n",
      "</tr>\n",
      "\r\n",
      "<tr><td style=\"text-align:left\">MSTParser</td>\n",
      "<td style=\"text-align:center\"> 91.4</td>\n",
      "<td style=\"text-align:center\"> 88.1</td>\n",
      "<td> 10</td>\n",
      "</tr>\n",
      "\r\n",
      "<tr><td style=\"text-align:left\">TurboParser</td>\n",
      "<td style=\"text-align:center\"> 92.3</td>\n",
      "<td style=\"text-align:center\"> 89.6</td>\n",
      "<td> 8</td>\n",
      "</tr>\n",
      "\r\n",
      "<tr><td style=\"text-align:left\"><a href=\"http://cs.stanford.edu/~danqi/papers/emnlp2014.pdf\">Stanford Neural Dependency Parser</a></td>\n",
      "<td style=\"text-align:center\"> 92.0</td>\n",
      "<td style=\"text-align:center\"> 89.7</td>\n",
      "<td> 654</td>\n",
      "</tr>\n",
      "\r\n",
      "<tr><td style=\"text-align:left\">Google</td>\n",
      "<td style=\"text-align:center\">&#160;94.3</td>\n",
      "<td style=\"text-align:center\"> 92.4</td>\n",
      "<td> ?</td>\n",
      "</tr>\n",
      "</tbody></table></div>\n",
      "<p>The last result is from Google &#8220;pulling out all the stops&#8221;, by&#160;putting massive amounts of resources into training the Stanford neural parser.</p>\n",
      "<h2>11. Theano</h2>\n",
      "<p><a href=\"http://www.marekrei.com/blog/wp-content/uploads/2015/08/14439811.png\"><img class=\" wp-image-370 size-full aligncenter\" src=\"http://www.marekrei.com/blog/wp-content/uploads/2015/08/14439811.png\" alt=\"\" width=\"399\" height=\"289\"></a></p>\n",
      "<p>Well, I knew a bit about <a href=\"http://deeplearning.net/software/theano/\">Theano</a> before, but I learned a whole lot more during the summer school. And it is pretty awesome.</p>\n",
      "<p>Since&#160;Theano&#160;originates from&#160;Montreal, it was especially helpful to be able to ask questions directly from the people who are developing it.</p>\n",
      "<p>Most of the information that was presented is available online, in the form of <a href=\"https://github.com/mila-udem/summerschool2015\">interactive python tutorials</a>.</p>\n",
      "<h2>12. Nvidia Digits</h2>\n",
      "<p>Nvidia has a toolkit called <a href=\"https://developer.nvidia.com/digits\">Digits</a> that trains and visualises complex neural network models without needing to write any code.&#160;And they&#8217;re selling <a href=\"https://developer.nvidia.com/devbox\">DevBox</a> &#8211; a machine customised for running Digits and other deep learning software (Theano, Caffe, etc). It comes with 4 Titan X GPUs and currently costs $15,000.</p>\n",
      "<h2>13. Fuel</h2>\n",
      "<p><a href=\"https://github.com/mila-udem/fuel\">Fuel</a> is a toolkit that manages iteration over your datasets &#8211; it can split them into minibatches, manage shuffling, apply various preprocessing steps, etc. There are prebuilt functions for some established datasets, such as MNIST, CIFAR-10, and Google&#8217;s 1B Word corpus.&#160;It is mainly designed for use with <a href=\"http://github.com/mila-udem/blocks\">Blocks</a>, a toolkit that simplifies network construction with Theano.</p>\n",
      "<h2>14. Multimodal linguistic regularities</h2>\n",
      "<p>Remember &#8220;king &#8211; man + woman = queen&#8221;? Turns out that works with images as well (Kiros et al., 2015).</p>\n",
      "<p><a href=\"http://www.marekrei.com/blog/wp-content/uploads/2015/08/talk_Montreal_part2_pdf.png\"><img class=\"alignnone size-full wp-image-371\" src=\"http://www.marekrei.com/blog/wp-content/uploads/2015/08/talk_Montreal_part2_pdf.png\" alt=\"talk_Montreal_part2_pdf\" width=\"1788\" height=\"1164\"></a></p>\n",
      "<h2>15.&#160;Taylor series approximation</h2>\n",
      "<p>When we are at point \\(x_0\\) and take a step to \\(x\\), then we can estimate the function value in the new location by knowing the derivatives, using the Taylor series approximation.</p>\n",
      "<p style=\"text-align: center;\">\\(<br>\n",
      "f(x) = f(x_0) + (x &#8211; x_0)f'(x) + \\frac{1}{2}&#160;(x &#8211; x_0)^2 f&#8221;(x) + &#8230;<br>\n",
      "\\)</p>\n",
      "<p>Similarly, we can estimate&#160;the loss of a function, when we update parameters \\(\\theta_0\\) to \\(\\theta\\).</p>\n",
      "<p style=\"text-align: center;\">\\(<br>\n",
      "J(\\theta)&#160;=J(\\theta_0) + (\\theta &#8211; \\theta_0)^T g + \\frac{1}{2}&#160;(\\theta &#8211; \\theta_0)^T&#160;H(\\theta &#8211; \\theta_0) + &#8230;<br>\n",
      "\\)</p>\n",
      "<p>where \\(g\\) contains the derivatives with respect to \\(\\theta\\), and \\(H\\) is the Hessian with second order derivatives&#160;with respect to \\(\\theta\\).</p>\n",
      "<p>This is the second-order Taylor approximation, but we could increase the accuracy by adding even higher-order derivatives.</p>\n",
      "<h2>16. Computational intensity</h2>\n",
      "<p>Adam Coates presented a strategy for analysing the speed of&#160;matrix operations on a GPU. It&#8217;s a simplified model that says your time is spent on either reading/writing to memory or doing calculations. It assumes you can do both in parallel so&#160;we are interested in which one of them takes more time.</p>\n",
      "<p>Let&#8217;s say we are multiplying a matrix with a vector:</p>\n",
      "<p><a href=\"http://www.marekrei.com/blog/wp-content/uploads/2015/08/dlss_systems_1.png\"><img class=\" wp-image-376 size-medium aligncenter\" src=\"http://www.marekrei.com/blog/wp-content/uploads/2015/08/dlss_systems_1-300x209.png\" alt=\"dlss_systems_1\" width=\"300\" height=\"209\"></a></p>\n",
      "<p>If \\(M=1024\\) and \\(N=512\\), then the number of bytes we need to read and store is:</p>\n",
      "<p style=\"text-align: center;\">\\( 4\\text{ bytes }\\times (1024&#160;\\times&#160;512 + 512 + 1024) = 2.1e6\\text{ bytes} \\)</p>\n",
      "<p>And the number of calculations&#160;we need to do is:</p>\n",
      "<p style=\"text-align: center;\">\\(2\\times 1024\\times 512 = 1e6\\text{ FLOPs}\\)</p>\n",
      "<p>If we have a GPU that can do&#160;6 TFLOP/s and has memory bandwidth of&#160; 300GB/s, then the&#160;total running time will be:</p>\n",
      "<p style=\"text-align: center;\">\\(\\text{max}\\{2.1e6\\text{ bytes }/ (300e9\\text{ bytes}/s), 1e6\\text{ FLOPs} / (6e12\\text{ FLOP}/s) \\} \\\\<br>\n",
      "= \\text{max}\\{ 7\\mu&#160;s, 0.16\\mu s \\} \\)</p>\n",
      "<p>This means the process is bounded by the \\(7\\mu s\\) spent on copying to/from the&#160;memory, and&#160;getting a faster GPU would not make any difference. As you can probably guess, this situation gets better with bigger matrices/vectors, and when doing matrix-matrix operations.</p>\n",
      "<p>Adam also described the idea of calculating the intensity of an operation:</p>\n",
      "<p style=\"text-align: center;\">Intensity = (# arithmetic ops) / (# bytes to load or store)</p>\n",
      "<p>In the previous scenario, this would be</p>\n",
      "<p style=\"text-align: center;\">Intensity = (1E6 FLOPs) / (2.1E6 bytes) = 0.5 FLOPs/bytes</p>\n",
      "<p>Low intensity means the system is bottlenecked on memory, and high intensity means it&#8217;s bottlenecked by the GPU speed. This can be visualised, in order to find which of the two needs to improve in order to speed up the whole system, and where the sweet spot lies.</p>\n",
      "<p><a href=\"http://www.marekrei.com/blog/wp-content/uploads/2015/08/dlss_systems_2.png\"><img class=\"alignnone size-full wp-image-377\" src=\"http://www.marekrei.com/blog/wp-content/uploads/2015/08/dlss_systems_2.png\" alt=\"dlss_systems_2\" width=\"1572\" height=\"609\"></a></p>\n",
      "<h2>17. Minibatches</h2>\n",
      "<p>Continuing from the intensity calculations, one way of increasing the intensity of your network&#160;(in order to be limited by computation instead of memory), is to process data in minibatches. This avoids some memory operations, and GPUs are great at processing large matrices in parallel.</p>\n",
      "<p>However, increasing the batch size too much will probably start to hurting the training algorithm and converging can take longer. It&#8217;s important to find a good balance in order to get the best results in the least amount of time.</p>\n",
      "<p><a href=\"http://www.marekrei.com/blog/wp-content/uploads/2015/08/dlss_systems_3.png\"><img class=\"alignnone size-full wp-image-388\" src=\"http://www.marekrei.com/blog/wp-content/uploads/2015/08/dlss_systems_3.png\" alt=\"dlss_systems_3\" width=\"1316\" height=\"682\"></a></p>\n",
      "<h2>18. Training on adversarial examples</h2>\n",
      "<p>It was recently revealed that&#160;neural networks are easily tricked by adversarial examples. In the example below, the image on the left is correctly classified as a goldfish. However, if we apply the noise pattern shown in the middle, resulting in the image on the right, the classifier becomes convinced this is a picture of a daisy. The image is from&#160;Andrej Karpathy&#8217;s blog post&#160;<a href=\"http://karpathy.github.io/2015/03/30/breaking-convnets/\">&#8220;Breaking Linear Classifiers on ImageNet&#8221;</a>, and you can read more about it there.&#160;<a href=\"http://www.marekrei.com/blog/wp-content/uploads/2015/08/fish.jpeg\"><img class=\"alignnone size-full wp-image-395\" src=\"http://www.marekrei.com/blog/wp-content/uploads/2015/08/fish.jpeg\" alt=\"fish\" width=\"1033\" height=\"327\"></a></p>\n",
      "<p>The noise pattern isn&#8217;t random though &#8211; the noise is carefully calculated, in order to trick the network. But the point remains: the image on the right is clearly still a goldfish and not a daisy.</p>\n",
      "<p>Apparently strategies like ensemble models, voting after multiple saccades, and unsupervised pretraining have all failed against this vulnerability. Applying heavy regularisation helps, but&#160;not before ruining the accuracy on the clean data.</p>\n",
      "<p>Ian Goodfellow presented the idea of training on these adversarial examples.&#160;They can be automatically generated and added to the training set. The results below show that in addition to helping with the adversarial cases, this also improves accuracy on the clean examples.<a href=\"http://www.marekrei.com/blog/wp-content/uploads/2015/08/goodfellow_adv.png\"><img class=\"alignnone size-full wp-image-396\" src=\"http://www.marekrei.com/blog/wp-content/uploads/2015/08/goodfellow_adv.png\" alt=\"goodfellow_adv\" width=\"1166\" height=\"780\"></a>Finally, we can improve this further by penalising the KL-divergence between the original predicted distribution and the predicted distribution on the adversarial example. This optimises the network to be more robust, and to predict similar class distributions for similar (adversarial) images.</p>\n",
      "<h2>19. Everything is language modelling</h2>\n",
      "<p>Phil Blunsom presented the idea that almost all NLP can be structured as a language model. We can do this by concatenating the output to the input and trying to predict the probability of the whole sequence.</p>\n",
      "<p>Translation:</p>\n",
      "<p style=\"text-align: center;\">\\(P(\\text{Les chiens aiment les os || Dogs love bones})\\)</p>\n",
      "<p style=\"text-align: left;\">Question answering:</p>\n",
      "<p style=\"text-align: center;\">\\(P(\\text{What do dogs love? || bones .})\\)</p>\n",
      "<p style=\"text-align: left;\">Dialogue:</p>\n",
      "<p style=\"text-align: center;\">\\(P(\\text{How are you? || Fine thanks. And you?})\\)</p>\n",
      "<p>The latter two need to be additionally conditioned on some world knowledge. The second part doesn&#8217;t even need to be words, but could be labels or some structured output like dependency relations.</p>\n",
      "<h2>20. SMT had a rough start</h2>\n",
      "<p>When Frederick Jelinek and his team at IBM submitted one of the first papers on statistical machine translation to COLING in 1988, they got the following anonymous review:</p>\n",
      "<p><a href=\"http://www.marekrei.com/blog/wp-content/uploads/2015/08/blunsom-lm-mt2.png\"><img class=\" wp-image-402 size-medium aligncenter\" src=\"http://www.marekrei.com/blog/wp-content/uploads/2015/08/blunsom-lm-mt2-270x300.png\" alt=\"blunsom-lm-mt2\" width=\"270\" height=\"300\"></a></p>\n",
      "<p><em>The validity of a statistical (information theoretic) approach to MT has indeed been&#160;</em><em>recognized, as the authors mention, by Weaver as early as 1949. And was universally&#160;</em><em>recognized as mistaken by 1950 (cf. Hutchins, MT &#8211; Past, Present, Future, Ellis&#160;</em><em>Horwood, 1986, p. 30ff and references therein). The crude force of computers is not&#160;</em><em>science. The paper is simply beyond the scope of COLING.</em></p>\n",
      "<h2>21. The state of Neural Machine Translation</h2>\n",
      "<p>Apparently a very simple neural model can produce surprisingly good results. An example of translating from Chinese to English, from Phil Blunsom&#8217;s slides:</p>\n",
      "<p><a href=\"http://www.marekrei.com/blog/wp-content/uploads/2015/08/blunsom-lm-mt.png\"><img class=\"alignnone size-full wp-image-403\" src=\"http://www.marekrei.com/blog/wp-content/uploads/2015/08/blunsom-lm-mt.png\" alt=\"blunsom-lm-mt\" width=\"924\" height=\"684\"></a></p>\n",
      "<p>In this model, the vectors for the Chinese words are simply added together to form a sentence vector. The decoder&#160;consists of a conditional language model which takes the sentence vector, together with vectors from the two recently generated English words, and generates the next word in the translation.</p>\n",
      "<p>However, neural models are still not outperforming the very best traditional MT systems. They do come very close though. Results from <a href=\"http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf\">&#8220;Sequence to Sequence Learning</a>&#160;<a href=\"http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf\">with Neural Networks&#8221;</a>&#160;by Sutskever et al. (2014):</p>\n",
      "<div class=\"table-responsive\"><table style=\"width:100%; \" class=\"easy-table easy-table-default \" border=\"0\">\n",
      "<thead>\r\n",
      "<tr><th>Model</th>\n",
      "<th>&#160;BLEU score</th>\n",
      "</tr>\n",
      "</thead>\n",
      "<tbody>\r\n",
      "<tr><td>Baseline</td>\n",
      "<td> 33.30</td>\n",
      "</tr>\n",
      "\r\n",
      "<tr><td>Best WMT'14 result</td>\n",
      "<td>&#160;37.0</td>\n",
      "</tr>\n",
      "\r\n",
      "<tr><td>Scoring with&#160;5 LSTMs</td>\n",
      "<td>&#160;36.5</td>\n",
      "</tr>\n",
      "\r\n",
      "<tr><td>Oracle (upper bound)</td>\n",
      "<td>&#160;&#8764;45</td>\n",
      "</tr>\n",
      "</tbody></table></div>\n",
      "<p><strong>Update:</strong> <a href=\"https://twitter.com/stanfordnlp\">@stanfordnlp</a> pointed out that there are some recent&#160;results where the neural model does indeed outperform the state-of-the-art traditional MT system. Check out &#8220;<a href=\"http://arxiv.org/pdf/1508.04025.pdf\">Effective Approaches to Attention-based Neural Machine Translation</a>&#8221; (Luong et. al., 2015).</p>\n",
      "<h2>22. MetaMind classifier demo</h2>\n",
      "<p>Richard Socher demonstrated the MetaMind&#160;<a href=\"https://www.metamind.io/vision/train\">image classification demo</a>, which you can train yourself by uploading images. I trained a classifier to detect Edison and Einstein (couldn&#8217;t find enough unique images of Tesla). 5 example images for both classes, testing on one held out image each. Seemed to work pretty well.</p>\n",
      "<p><a href=\"http://www.marekrei.com/blog/wp-content/uploads/2015/08/edison_vs_einstein.png\"><img class=\"alignnone size-full wp-image-406\" src=\"http://www.marekrei.com/blog/wp-content/uploads/2015/08/edison_vs_einstein.png\" alt=\"edison_vs_einstein\" width=\"1158\" height=\"417\"></a></p>\n",
      "<h2>23. Optimising gradient updates</h2>\n",
      "<p>Mark Schmidt gave two presentations about numerical optimisation in different scenarios.</p>\n",
      "<p>In a <strong>deterministic</strong> gradient method we calculate the gradient over the whole dataset and then apply the update. The iteration cost is linear with the dataset size.</p>\n",
      "<p>In&#160;<strong>stochastic</strong> gradient methods we calculate the gradient on one datapoint and then apply the update. The iteration cost is independent of the dataset size.</p>\n",
      "<p>Each iteration of the stochastic gradient descent is much faster, but it usually takes many more iterations to train the network, as this graph illustrates:</p>\n",
      "<p><a href=\"http://www.marekrei.com/blog/wp-content/uploads/2015/08/2015_DLSS_ConvexOptimization.png\"><img class=\" wp-image-408 size-medium aligncenter\" src=\"http://www.marekrei.com/blog/wp-content/uploads/2015/08/2015_DLSS_ConvexOptimization-300x233.png\" alt=\"2015_DLSS_ConvexOptimization\" width=\"300\" height=\"233\"></a></p>\n",
      "<p>In order to get the best of both worlds, we can use batching. More specifically, we could do one pass of the dataset with stochastic gradient descent, in order to quickly get on the right track, and then start increasing the batch size. The gradient error decreases as the batch size increases, although eventually the iteration cost will become dependent on the dataset size again.</p>\n",
      "<p>Stochastic Average Gradient (SAG) is a method that gets around this, providing a linear convergence rate with only 1 gradient per iteration. Unfortunately, it is not feasible for large neural networks, as it needs to remember the gradient updates&#160;for every datapoint, leading to large memory requirements.&#160;Stochastic Variance-Reduced Gradient (SVRG) is another method that reduces this memory cost, and&#160;only needs 2 gradient calculations per iteration (plus occasional full passes).</p>\n",
      "<p>Mark said a student of his implemented a variety of optimisation methods (AdaGrad, momentum, SAG, etc). When asked, what he would use in a black box neural network system, the student said two methods: <a href=\"http://arxiv.org/pdf/1412.6606.pdf\">Streaming SVRG</a> (Frostig et al., 2015), and a method they haven&#8217;t published yet.</p>\n",
      "<h2>24. Theano profiling</h2>\n",
      "<p>If you put &#8220;profile=True&#8221; into THEANO_FLAGS, it will analyse your program, showing a breakdown of how much is spent on each operation. Very handy for finding bottlenecks.</p>\n",
      "<h2>25.&#160;Adversarial nets framework</h2>\n",
      "<p>Following on from Ian Goodfellow&#8217;s talk on adversarial examples, Yoshua Bengio talked about having two systems competing&#160;with each other.</p>\n",
      "<p>System D is a discriminative system that aims to classify between real data and artificially generated data.</p>\n",
      "<p>System G is a generative system, that tries to generate artificial data, which D would incorrectly classify as real.</p>\n",
      "<p>As we train one, the other needs to get better as well. In practice this does work, although&#160;the step needs to be quite small to make sure D can keep up with G. Below are some examples from &#8220;<a href=\"http://arxiv.org/abs/1506.05751\">Deep Generative Image Models using a&#160;Laplacian Pyramid of Adversarial Networks</a>&#8221; &#8211; a more advanced version of this model which tries to generate images of churches.</p>\n",
      "<p><a href=\"http://www.marekrei.com/blog/wp-content/uploads/2015/08/denton_generating_images.png\"><img class=\"alignnone size-full wp-image-409\" src=\"http://www.marekrei.com/blog/wp-content/uploads/2015/08/denton_generating_images.png\" alt=\"denton_generating_images\" width=\"1456\" height=\"802\"></a></p>\n",
      "<h2>26. arXiv.org numbering</h2>\n",
      "<p>The arXiv number contains the year and month of the submission, followed by the sequence number. So paper&#160;1508.03854 was number&#160;3854 in August 2015. Good to know.</p>\n",
      "<h2></h2>\n",
      "\t\t\t\t\t\n",
      "\t\t\t\t\t\n",
      "\t\t\t</div>\n",
      "\t\t\t<!-- / .content -->\n",
      "\t\t\t\n",
      "\t\t\t<footer>\n",
      "\t\t\t  \t\t\t\t  <span class=\"author\"><span class=\"author-label\">Written by</span> <a href=\"http://www.marekrei.com/blog/author/marek/\" title=\"Posts by Marek\" rel=\"author\">Marek</a></span>\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<span class=\"categories\">\n",
      "\t\t\t\t\t\t<span class=\"categories-label\">Posted in</span> <a href=\"http://www.marekrei.com/blog/category/uncategorized/\" rel=\"category tag\">Uncategorized</a>\t\t\t\t\t</span>\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t</footer>\n",
      "\t\t</article>\n",
      "\t\t<!-- / #post-333 -->\n",
      "\n",
      "\t\t\n",
      "<section id=\"comments\">\n",
      "\t\n",
      "\t\t\t<h1 id=\"comments-title\">10 comments</h1>\n",
      "\n",
      "\t\t\n",
      "\t\t<ol id=\"comment-list\">\t<li class=\"comment even thread-even depth-1\" id=\"comment-21698\">\n",
      "\t\t<article>\n",
      "\t\t\t<header class=\"comment-header\">\n",
      "\t\t\t  <figure><img alt=\"\" src=\"http://1.gravatar.com/avatar/4b45b79e5550794bf6222a6157c595ed?s=40&amp;d=mm&amp;r=g\" srcset=\"http://1.gravatar.com/avatar/4b45b79e5550794bf6222a6157c595ed?s=80&amp;d=mm&amp;r=g 2x\" class=\"avatar avatar-40 photo\" height=\"40\" width=\"40\"></figure>  \t\t\t<time><a href=\"http://www.marekrei.com/blog/26-things-i-learned-in-the-deep-learning-summer-school/#comment-21698\">September 10, 2015 - 4:37 pm</a></time>\n",
      "\n",
      "  \t\t\t  \t\t\t  <cite>Harri</cite>  \t\t\t  \t\t</header>\n",
      "\n",
      "  \t\t\n",
      "  \t\t<p>It seems like min and max are the wrong way around in the definition of `ramp&#8217;. Enjoyed the post.</p>\n",
      "\n",
      "  \t\t<div class=\"reply\">\n",
      "  \t\t\t<a rel=\"nofollow\" class=\"comment-reply-link\" href=\"http://www.marekrei.com/blog/26-things-i-learned-in-the-deep-learning-summer-school/?replytocom=21698#respond\" onclick='return addComment.moveForm( \"comment-21698\", \"21698\", \"respond\", \"333\" )' aria-label=\"Reply to Harri\">Reply</a>\n",
      "  \t\t\t  \t\t</div><!-- .reply -->\n",
      "\t\t  </article>\n",
      "\t</li><!-- #comment-## -->\n",
      "\t<li class=\"comment odd alt thread-odd thread-alt depth-1\" id=\"comment-21701\">\n",
      "\t\t<article>\n",
      "\t\t\t<header class=\"comment-header\">\n",
      "\t\t\t  <figure><img alt=\"\" src=\"http://2.gravatar.com/avatar/ba4ca418749e7bcd60522ed2ec32638c?s=40&amp;d=mm&amp;r=g\" srcset=\"http://2.gravatar.com/avatar/ba4ca418749e7bcd60522ed2ec32638c?s=80&amp;d=mm&amp;r=g 2x\" class=\"avatar avatar-40 photo\" height=\"40\" width=\"40\"></figure>  \t\t\t<time><a href=\"http://www.marekrei.com/blog/26-things-i-learned-in-the-deep-learning-summer-school/#comment-21701\">September 10, 2015 - 7:03 pm</a></time>\n",
      "\n",
      "  \t\t\t  \t\t\t  <cite>Drew Cummins</cite>  \t\t\t  \t\t</header>\n",
      "\n",
      "  \t\t\n",
      "  \t\t<p>Nice article! Min and max are backwards in the ramp function, but I guess it&#8217;s from someone else&#8217;s presentation?</p>\n",
      "\n",
      "  \t\t<div class=\"reply\">\n",
      "  \t\t\t<a rel=\"nofollow\" class=\"comment-reply-link\" href=\"http://www.marekrei.com/blog/26-things-i-learned-in-the-deep-learning-summer-school/?replytocom=21701#respond\" onclick='return addComment.moveForm( \"comment-21701\", \"21701\", \"respond\", \"333\" )' aria-label=\"Reply to Drew Cummins\">Reply</a>\n",
      "  \t\t\t  \t\t</div><!-- .reply -->\n",
      "\t\t  </article>\n",
      "\t</li><!-- #comment-## -->\n",
      "\t<li class=\"comment even thread-even depth-1\" id=\"comment-21718\">\n",
      "\t\t<article>\n",
      "\t\t\t<header class=\"comment-header\">\n",
      "\t\t\t  <figure><img alt=\"\" src=\"http://1.gravatar.com/avatar/a6364a1e3d4cf1707972d98b99236598?s=40&amp;d=mm&amp;r=g\" srcset=\"http://1.gravatar.com/avatar/a6364a1e3d4cf1707972d98b99236598?s=80&amp;d=mm&amp;r=g 2x\" class=\"avatar avatar-40 photo\" height=\"40\" width=\"40\"></figure>  \t\t\t<time><a href=\"http://www.marekrei.com/blog/26-things-i-learned-in-the-deep-learning-summer-school/#comment-21718\">September 11, 2015 - 2:50 pm</a></time>\n",
      "\n",
      "  \t\t\t  \t\t\t  <cite>Lajanugen</cite>  \t\t\t  \t\t</header>\n",
      "\n",
      "  \t\t\n",
      "  \t\t<p>Nice write-up. Found a lot of useful information here.</p>\n",
      "\n",
      "  \t\t<div class=\"reply\">\n",
      "  \t\t\t<a rel=\"nofollow\" class=\"comment-reply-link\" href=\"http://www.marekrei.com/blog/26-things-i-learned-in-the-deep-learning-summer-school/?replytocom=21718#respond\" onclick='return addComment.moveForm( \"comment-21718\", \"21718\", \"respond\", \"333\" )' aria-label=\"Reply to Lajanugen\">Reply</a>\n",
      "  \t\t\t  \t\t</div><!-- .reply -->\n",
      "\t\t  </article>\n",
      "\t</li><!-- #comment-## -->\n",
      "\t<li class=\"comment odd alt thread-odd thread-alt depth-1\" id=\"comment-21720\">\n",
      "\t\t<article>\n",
      "\t\t\t<header class=\"comment-header\">\n",
      "\t\t\t  <figure><img alt=\"\" src=\"http://1.gravatar.com/avatar/d2d95adaf481e36a7fa349032f7b8e42?s=40&amp;d=mm&amp;r=g\" srcset=\"http://1.gravatar.com/avatar/d2d95adaf481e36a7fa349032f7b8e42?s=80&amp;d=mm&amp;r=g 2x\" class=\"avatar avatar-40 photo\" height=\"40\" width=\"40\"></figure>  \t\t\t<time><a href=\"http://www.marekrei.com/blog/26-things-i-learned-in-the-deep-learning-summer-school/#comment-21720\">September 11, 2015 - 3:13 pm</a></time>\n",
      "\n",
      "  \t\t\t  \t\t\t  <cite>Simon</cite>  \t\t\t  \t\t</header>\n",
      "\n",
      "  \t\t\n",
      "  \t\t<p>Excellent post. In the ramp function in 3. I think you have the max and min the wrong way around. The function you have will always output -1.</p>\n",
      "\n",
      "  \t\t<div class=\"reply\">\n",
      "  \t\t\t<a rel=\"nofollow\" class=\"comment-reply-link\" href=\"http://www.marekrei.com/blog/26-things-i-learned-in-the-deep-learning-summer-school/?replytocom=21720#respond\" onclick='return addComment.moveForm( \"comment-21720\", \"21720\", \"respond\", \"333\" )' aria-label=\"Reply to Simon\">Reply</a>\n",
      "  \t\t\t  \t\t</div><!-- .reply -->\n",
      "\t\t  </article>\n",
      "\t</li><!-- #comment-## -->\n",
      "\t<li class=\"comment even thread-even depth-1\" id=\"comment-21739\">\n",
      "\t\t<article>\n",
      "\t\t\t<header class=\"comment-header\">\n",
      "\t\t\t  <figure><img alt=\"\" src=\"http://1.gravatar.com/avatar/d58fd48dfcd62a44079c55c769f2d924?s=40&amp;d=mm&amp;r=g\" srcset=\"http://1.gravatar.com/avatar/d58fd48dfcd62a44079c55c769f2d924?s=80&amp;d=mm&amp;r=g 2x\" class=\"avatar avatar-40 photo\" height=\"40\" width=\"40\"></figure>  \t\t\t<time><a href=\"http://www.marekrei.com/blog/26-things-i-learned-in-the-deep-learning-summer-school/#comment-21739\">September 12, 2015 - 6:25 am</a></time>\n",
      "\n",
      "  \t\t\t  \t\t\t  <cite><a href=\"http://anhnguyen.me\" rel=\"external nofollow\" class=\"url\">Anh</a></cite>  \t\t\t  \t\t</header>\n",
      "\n",
      "  \t\t\n",
      "  \t\t<p>Hi Marek,</p>\n",
      "<p>This is a super useful post!! Thanks for sharing cool things @ DL summer school. <img src=\"http://www.marekrei.com/blog/wp-includes/images/smilies/simple-smile.png\" alt=\":)\" class=\"wp-smiley\" style=\"height: 1em; max-height: 1em;\"></p>\n",
      "\n",
      "  \t\t<div class=\"reply\">\n",
      "  \t\t\t<a rel=\"nofollow\" class=\"comment-reply-link\" href=\"http://www.marekrei.com/blog/26-things-i-learned-in-the-deep-learning-summer-school/?replytocom=21739#respond\" onclick='return addComment.moveForm( \"comment-21739\", \"21739\", \"respond\", \"333\" )' aria-label=\"Reply to Anh\">Reply</a>\n",
      "  \t\t\t  \t\t</div><!-- .reply -->\n",
      "\t\t  </article>\n",
      "\t</li><!-- #comment-## -->\n",
      "\t<li class=\"comment odd alt thread-odd thread-alt depth-1\" id=\"comment-21911\">\n",
      "\t\t<article>\n",
      "\t\t\t<header class=\"comment-header\">\n",
      "\t\t\t  <figure><img alt=\"\" src=\"http://1.gravatar.com/avatar/d3ba9d443fec7d2ce0d5edc6815b678d?s=40&amp;d=mm&amp;r=g\" srcset=\"http://1.gravatar.com/avatar/d3ba9d443fec7d2ce0d5edc6815b678d?s=80&amp;d=mm&amp;r=g 2x\" class=\"avatar avatar-40 photo\" height=\"40\" width=\"40\"></figure>  \t\t\t<time><a href=\"http://www.marekrei.com/blog/26-things-i-learned-in-the-deep-learning-summer-school/#comment-21911\">September 15, 2015 - 7:02 pm</a></time>\n",
      "\n",
      "  \t\t\t  \t\t\t  <cite>Claude Coulombe</cite>  \t\t\t  \t\t</header>\n",
      "\n",
      "  \t\t\n",
      "  \t\t<p>Greetings Marek, quite a good summary! I was there and I&#8217;ve learned a lot too. </p>\n",
      "<p>There were also very good talks on NLP and DL by researchers at Google (Phil Blunsom, Ian Goodfellow), Baidu (Adam Cotes), Twitter (Hugo Larochelle), Microsoft (Leon Bottou), MetaMind (Richard Socher) and Stanford University (Chris Manning).</p>\n",
      "<p>We can add, a lot of material about the different neural network architectures: Autoencoders, RBM (Restricted Boltzmann Machines), CNN (Convolutional Neural Networks), DBM (Deep Boltzmann Machines), DBN (Deep Belief Networks), RNN (Recurrent Neural Networks), LSTM (Long Short Term Memory), etc.</p>\n",
      "\n",
      "  \t\t<div class=\"reply\">\n",
      "  \t\t\t<a rel=\"nofollow\" class=\"comment-reply-link\" href=\"http://www.marekrei.com/blog/26-things-i-learned-in-the-deep-learning-summer-school/?replytocom=21911#respond\" onclick='return addComment.moveForm( \"comment-21911\", \"21911\", \"respond\", \"333\" )' aria-label=\"Reply to Claude Coulombe\">Reply</a>\n",
      "  \t\t\t  \t\t</div><!-- .reply -->\n",
      "\t\t  </article>\n",
      "\t</li><!-- #comment-## -->\n",
      "\t<li class=\"comment even thread-even depth-1\" id=\"comment-21925\">\n",
      "\t\t<article>\n",
      "\t\t\t<header class=\"comment-header\">\n",
      "\t\t\t  <figure><img alt=\"\" src=\"http://1.gravatar.com/avatar/18452c228ede1b8db735a6c310068947?s=40&amp;d=mm&amp;r=g\" srcset=\"http://1.gravatar.com/avatar/18452c228ede1b8db735a6c310068947?s=80&amp;d=mm&amp;r=g 2x\" class=\"avatar avatar-40 photo\" height=\"40\" width=\"40\"></figure>  \t\t\t<time><a href=\"http://www.marekrei.com/blog/26-things-i-learned-in-the-deep-learning-summer-school/#comment-21925\">September 16, 2015 - 8:30 am</a></time>\n",
      "\n",
      "  \t\t\t  \t\t\t  <cite><a href=\"https://github.com/petrux\" rel=\"external nofollow\" class=\"url\">petrux</a></cite>  \t\t\t  \t\t</header>\n",
      "\n",
      "  \t\t\n",
      "  \t\t<p>Nice post! Thanks for sharing your experience of the Summer School. If you don&#8217;t mind I would like to add a consideration and a question.</p>\n",
      "<p><cite><br>\n",
      "So it seems that, at the moment, models using the parse tree are beating simpler approaches. I&#8217;m curious to see if and when the next syntax-free approach will emerge that will advance this race. After all, the goal of many neural models is not to discard the underlying grammar, but to implicitly capture it in the same network.<br>\n",
      "</cite>  </p>\n",
      "<p>Well, the syntax-free approach needs a larger amount of training data but the the feature engineering effort should be reduced. At the end of the day, it&#8217;s just sampling: syntax-free sampling needs more sampling activity, but it&#8217;s simpler. And you are right: it will be really interesting to see how this confrontation will evolve. </p>\n",
      "<p>My question is about the Google dependency parsing. Do you have any link to a deeper description of the project? Thanks a lot!</p>\n",
      "\n",
      "  \t\t<div class=\"reply\">\n",
      "  \t\t\t<a rel=\"nofollow\" class=\"comment-reply-link\" href=\"http://www.marekrei.com/blog/26-things-i-learned-in-the-deep-learning-summer-school/?replytocom=21925#respond\" onclick='return addComment.moveForm( \"comment-21925\", \"21925\", \"respond\", \"333\" )' aria-label=\"Reply to petrux\">Reply</a>\n",
      "  \t\t\t  \t\t</div><!-- .reply -->\n",
      "\t\t  </article>\n",
      "\t<ul class=\"children\">\n",
      "\t<li class=\"comment byuser comment-author-marek bypostauthor odd alt depth-2\" id=\"comment-21973\">\n",
      "\t\t<article>\n",
      "\t\t\t<header class=\"comment-header\">\n",
      "\t\t\t  <figure><img alt=\"\" src=\"http://2.gravatar.com/avatar/e4b5654c9440a13238a82252c1d9efe8?s=40&amp;d=mm&amp;r=g\" srcset=\"http://2.gravatar.com/avatar/e4b5654c9440a13238a82252c1d9efe8?s=80&amp;d=mm&amp;r=g 2x\" class=\"avatar avatar-40 photo\" height=\"40\" width=\"40\"></figure>  \t\t\t<time><a href=\"http://www.marekrei.com/blog/26-things-i-learned-in-the-deep-learning-summer-school/#comment-21973\">September 18, 2015 - 5:14 pm</a></time>\n",
      "\n",
      "  \t\t\t  \t\t\t  <cite><a href=\"http://www.marekrei.com/blog/author/marek/\">Marek</a></cite>\n",
      "  \t\t\t  \t\t</header>\n",
      "\n",
      "  \t\t\n",
      "  \t\t<p>Thanks for the comment.</p>\n",
      "<p>As far as I know, the details of the Google parsing result have not been released. It was implied at the talk that it was a version of the Stanford parser, modified to take advantage of Google computing capabilities (a bigger model, trained for longer).</p>\n",
      "\n",
      "  \t\t<div class=\"reply\">\n",
      "  \t\t\t<a rel=\"nofollow\" class=\"comment-reply-link\" href=\"http://www.marekrei.com/blog/26-things-i-learned-in-the-deep-learning-summer-school/?replytocom=21973#respond\" onclick='return addComment.moveForm( \"comment-21973\", \"21973\", \"respond\", \"333\" )' aria-label=\"Reply to Marek\">Reply</a>\n",
      "  \t\t\t  \t\t</div><!-- .reply -->\n",
      "\t\t  </article>\n",
      "\t<ul class=\"children\">\n",
      "\t<li class=\"comment even depth-3\" id=\"comment-22084\">\n",
      "\t\t<article>\n",
      "\t\t\t<header class=\"comment-header\">\n",
      "\t\t\t  <figure><img alt=\"\" src=\"http://1.gravatar.com/avatar/18452c228ede1b8db735a6c310068947?s=40&amp;d=mm&amp;r=g\" srcset=\"http://1.gravatar.com/avatar/18452c228ede1b8db735a6c310068947?s=80&amp;d=mm&amp;r=g 2x\" class=\"avatar avatar-40 photo\" height=\"40\" width=\"40\"></figure>  \t\t\t<time><a href=\"http://www.marekrei.com/blog/26-things-i-learned-in-the-deep-learning-summer-school/#comment-22084\">September 21, 2015 - 8:14 am</a></time>\n",
      "\n",
      "  \t\t\t  \t\t\t  <cite><a href=\"https://github.com/petrux\" rel=\"external nofollow\" class=\"url\">petrux</a></cite>  \t\t\t  \t\t</header>\n",
      "\n",
      "  \t\t\n",
      "  \t\t<p>I see. Thanks for the reply and god luck!</p>\n",
      "\n",
      "  \t\t<div class=\"reply\">\n",
      "  \t\t\t<a rel=\"nofollow\" class=\"comment-reply-link\" href=\"http://www.marekrei.com/blog/26-things-i-learned-in-the-deep-learning-summer-school/?replytocom=22084#respond\" onclick='return addComment.moveForm( \"comment-22084\", \"22084\", \"respond\", \"333\" )' aria-label=\"Reply to petrux\">Reply</a>\n",
      "  \t\t\t  \t\t</div><!-- .reply -->\n",
      "\t\t  </article>\n",
      "\t</li><!-- #comment-## -->\n",
      "</ul><!-- .children -->\n",
      "</li><!-- #comment-## -->\n",
      "</ul><!-- .children -->\n",
      "</li><!-- #comment-## -->\n",
      "\t<li class=\"comment odd alt thread-odd thread-alt depth-1\" id=\"comment-22111\">\n",
      "\t\t<article>\n",
      "\t\t\t<header class=\"comment-header\">\n",
      "\t\t\t  <figure><img alt=\"\" src=\"http://1.gravatar.com/avatar/49baea512531cb92136f400f842d5e3a?s=40&amp;d=mm&amp;r=g\" srcset=\"http://1.gravatar.com/avatar/49baea512531cb92136f400f842d5e3a?s=80&amp;d=mm&amp;r=g 2x\" class=\"avatar avatar-40 photo\" height=\"40\" width=\"40\"></figure>  \t\t\t<time><a href=\"http://www.marekrei.com/blog/26-things-i-learned-in-the-deep-learning-summer-school/#comment-22111\">September 22, 2015 - 3:46 pm</a></time>\n",
      "\n",
      "  \t\t\t  \t\t\t  <cite><a href=\"http://in.linkedin.com/farhanhubble\" rel=\"external nofollow\" class=\"url\">Farhan Ahmad</a></cite>  \t\t\t  \t\t</header>\n",
      "\n",
      "  \t\t\n",
      "  \t\t<p>Thank you for such great post and lots of great references. I enjoyed the section on neural machine translation the most.</p>\n",
      "\n",
      "  \t\t<div class=\"reply\">\n",
      "  \t\t\t<a rel=\"nofollow\" class=\"comment-reply-link\" href=\"http://www.marekrei.com/blog/26-things-i-learned-in-the-deep-learning-summer-school/?replytocom=22111#respond\" onclick='return addComment.moveForm( \"comment-22111\", \"22111\", \"respond\", \"333\" )' aria-label=\"Reply to Farhan Ahmad\">Reply</a>\n",
      "  \t\t\t  \t\t</div><!-- .reply -->\n",
      "\t\t  </article>\n",
      "\t</li><!-- #comment-## -->\n",
      "</ol>\n",
      "\n",
      "\t\t\t\n",
      "\t\t\t\t\t\t\t<div id=\"respond\" class=\"comment-respond\">\n",
      "\t\t\t\t<h3 id=\"reply-title\" class=\"comment-reply-title\">Post a comment <small><a rel=\"nofollow\" id=\"cancel-comment-reply-link\" href=\"/blog/26-things-i-learned-in-the-deep-learning-summer-school/#respond\" style=\"display:none;\">Cancel reply</a></small></h3>\n",
      "\t\t\t\t\t\t\t\t\t<form action=\"http://www.marekrei.com/blog/wp-comments-post.php\" method=\"post\" id=\"commentform\" class=\"comment-form\">\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<label for=\"comment-author\">Name <span class=\"required\">(required)</span></label> <input id=\"comment-author\" name=\"author\" type=\"text\" value=\"\" size=\"30\" aria-required=\"true\">\n",
      "<label for=\"comment-email\">Email <span class=\"required\">(required - will be kept a secret)</span></label> <input id=\"comment-email\" name=\"email\" type=\"text\" value=\"\" size=\"30\" aria-required=\"true\">\n",
      "<label for=\"comment-url\">Website</label><input id=\"comment-url\" name=\"url\" type=\"text\" value=\"\" size=\"30\">\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t<label for=\"comment\">Comment</label><textarea id=\"comment\" name=\"comment\" cols=\"45\" rows=\"8\" aria-required=\"true\"></textarea>\t\t\t\t\t\t<dl class=\"form-allowed-tags\"><dt>You may use the following <abbr title=\"HyperText Markup Language\">HTML</abbr>:</dt> <dd><code>&lt;a href=\"\" title=\"\"&gt; &lt;abbr title=\"\"&gt; &lt;acronym title=\"\"&gt; &lt;b&gt; &lt;blockquote cite=\"\"&gt; &lt;cite&gt; &lt;code&gt; &lt;del datetime=\"\"&gt; &lt;em&gt; &lt;i&gt; &lt;q cite=\"\"&gt; &lt;s&gt; &lt;strike&gt; &lt;strong&gt; </code></dd></dl>\n",
      "\t\t\t\t\t\t<p class=\"form-submit\"><input name=\"submit\" type=\"submit\" id=\"submit\" class=\"submit\" value=\"Post comment\"> <input type=\"hidden\" name=\"comment_post_ID\" value=\"333\" id=\"comment_post_ID\">\n",
      "<input type=\"hidden\" name=\"comment_parent\" id=\"comment_parent\" value=\"0\">\n",
      "</p><p style=\"display: none;\"><input type=\"hidden\" id=\"akismet_comment_nonce\" name=\"akismet_comment_nonce\" value=\"b3133362b4\"></p><p style=\"display: none;\"><input type=\"hidden\" id=\"ak_js\" name=\"ak_js\" value=\"12\"></p>\t\t\t\t\t</form>\n",
      "\t\t\t\t\t\t\t</div><!-- #respond -->\n",
      "\t\t\t\n",
      "</section>\n",
      "<!-- / #comments -->\n",
      "\t\t\n",
      "\t\t\t\t  <nav class=\"post-nav\" role=\"navigation\">\n",
      "\t\t\t\t<div class=\"nav-previous\"><a href=\"http://www.marekrei.com/blog/transforming-images-to-feature-vectors/\" rel=\"prev\"><span class=\"meta-nav\"></span> Transforming images to feature vectors</a></div>\n",
      "\t\t\t\t<div class=\"nav-next\"></div>\n",
      "\t\t\t</nav>\n",
      "\t\t\t<!-- / .post-nav -->\n",
      "\t\t\t\t\n",
      "\t\t\n",
      "\n",
      "\t\t</section>\n",
      "\t\t<!-- / #content -->\n",
      "\t\t\n",
      "\t\t\n",
      "\t\t\t\t\t<aside id=\"primary\" role=\"complementary\">\n",
      "\t\t\t\t<section id=\"search-2\" class=\"widget widget_search\"><form role=\"search\" method=\"get\" id=\"searchform\" class=\"searchform\" action=\"http://www.marekrei.com/blog/\">\n",
      "\t\t\t\t<div>\n",
      "\t\t\t\t\t<label class=\"screen-reader-text\" for=\"s\">Search for:</label>\n",
      "\t\t\t\t\t<input type=\"text\" value=\"\" name=\"s\" id=\"s\">\n",
      "\t\t\t\t\t<input type=\"submit\" id=\"searchsubmit\" value=\"Search\">\n",
      "\t\t\t\t</div>\n",
      "\t\t\t</form></section>\t\t<section id=\"recent-posts-2\" class=\"widget widget_recent_entries\">\t\t<h3 class=\"title\">Recent Posts</h3>\t\t<ul>\n",
      "\t\t\t\t\t<li>\n",
      "\t\t\t\t<a href=\"/blog/26-things-i-learned-in-the-deep-learning-summer-school/\">26 Things I Learned in the Deep Learning Summer School</a>\n",
      "\t\t\t\t\t\t</li>\n",
      "\t\t\t\t\t<li>\n",
      "\t\t\t\t<a href=\"/blog/transforming-images-to-feature-vectors/\">Transforming images to feature vectors</a>\n",
      "\t\t\t\t\t\t</li>\n",
      "\t\t\t\t\t<li>\n",
      "\t\t\t\t<a href=\"/blog/linguistic-regularities-word-representations/\">Linguistic Regularities in Word Representations</a>\n",
      "\t\t\t\t\t\t</li>\n",
      "\t\t\t\t\t<li>\n",
      "\t\t\t\t<a href=\"/blog/multilingual-semantic-models/\">Multilingual Semantic Models</a>\n",
      "\t\t\t\t\t\t</li>\n",
      "\t\t\t\t\t<li>\n",
      "\t\t\t\t<a href=\"/blog/political-ideology-detection/\">Political ideology detection</a>\n",
      "\t\t\t\t\t\t</li>\n",
      "\t\t\t\t\t<li>\n",
      "\t\t\t\t<a href=\"/blog/dont-count-predict/\">Don&#8217;t count, predict</a>\n",
      "\t\t\t\t\t\t</li>\n",
      "\t\t\t\t\t<li>\n",
      "\t\t\t\t<a href=\"/blog/neural-networks-part-3-network/\">Neural Networks, Part 3: The Network</a>\n",
      "\t\t\t\t\t\t</li>\n",
      "\t\t\t\t\t<li>\n",
      "\t\t\t\t<a href=\"/blog/normalise-feature-vectors/\">How to normalise feature vectors</a>\n",
      "\t\t\t\t\t\t</li>\n",
      "\t\t\t\t\t<li>\n",
      "\t\t\t\t<a href=\"/blog/neural-networks-part-2-the-neuron/\">Neural Networks, Part 2: The Neuron</a>\n",
      "\t\t\t\t\t\t</li>\n",
      "\t\t\t\t\t<li>\n",
      "\t\t\t\t<a href=\"/blog/neural-networks-part-1-background/\">Neural Networks, Part 1: Background</a>\n",
      "\t\t\t\t\t\t</li>\n",
      "\t\t\t\t</ul>\n",
      "\t\t</section><section id=\"archives-2\" class=\"widget widget_archive\"><h3 class=\"title\">Archives</h3>\t\t<ul>\n",
      "\t<li><a href=\"http://www.marekrei.com/blog/2015/08/\">August 2015</a></li>\n",
      "\t<li><a href=\"http://www.marekrei.com/blog/2015/06/\">June 2015</a></li>\n",
      "\t<li><a href=\"http://www.marekrei.com/blog/2014/10/\">October 2014</a></li>\n",
      "\t<li><a href=\"http://www.marekrei.com/blog/2014/09/\">September 2014</a></li>\n",
      "\t<li><a href=\"http://www.marekrei.com/blog/2014/02/\">February 2014</a></li>\n",
      "\t<li><a href=\"http://www.marekrei.com/blog/2014/01/\">January 2014</a></li>\n",
      "\t\t</ul>\n",
      "</section><section id=\"categories-2\" class=\"widget widget_categories\"><h3 class=\"title\">Categories</h3>\t\t<ul>\n",
      "\t<li class=\"cat-item cat-item-3\"><a href=\"http://www.marekrei.com/blog/category/neural-networks/\">Neural Networks</a>\n",
      "</li>\n",
      "\t<li class=\"cat-item cat-item-4\"><a href=\"http://www.marekrei.com/blog/category/resources/\">Resources</a>\n",
      "</li>\n",
      "\t<li class=\"cat-item cat-item-1\"><a href=\"http://www.marekrei.com/blog/category/uncategorized/\">Uncategorized</a>\n",
      "</li>\n",
      "\t\t</ul>\n",
      "</section><section id=\"meta-2\" class=\"widget widget_meta\"><h3 class=\"title\">Meta</h3>\t\t\t<ul>\n",
      "\t\t\t\t\t\t<li><a rel=\"nofollow\" href=\"http://www.marekrei.com/blog/wp-login.php\">Log in</a></li>\n",
      "\t\t\t<li><a href=\"http://www.marekrei.com/blog/feed/\">Entries <abbr title=\"Really Simple Syndication\">RSS</abbr></a></li>\n",
      "\t\t\t<li><a href=\"http://www.marekrei.com/blog/comments/feed/\">Comments <abbr title=\"Really Simple Syndication\">RSS</abbr></a></li>\n",
      "<li><a href=\"https://wordpress.org/\" title=\"Powered by WordPress, state-of-the-art semantic personal publishing platform.\">WordPress.org</a></li>\t\t\t</ul>\n",
      "</section>\t\t</aside>\n",
      "\t\t<!-- / #primary -->\n",
      "    \n",
      "    \t\t\t\n",
      "\t\t\n",
      "\t\t<footer id=\"footer\">\n",
      "\t\t\t\t\t</footer>\n",
      "\t\t<!-- / #footer -->\n",
      "\t</div>\n",
      "\t<!-- / #wrapper -->\n",
      "</div>\n",
      "<!-- / #site -->\n",
      "\n",
      "<!-- MathJax Latex Plugin installed -->\n",
      "\t<script>\n",
      "\tMBP.scaleFix();\n",
      "\tMBP.hideUrlBar();\n",
      "\t</script>\n",
      "\t<!--[if (lt IE 9) & (!IEMobile)]>\r",
      "<script type=\"text/javascript\" src=\"http://www.marekrei.com/blog/wp-content/themes/blaskan/js/libs/selectivizr.1.0.3b.js\"></script>\r",
      "<script type=\"text/javascript\" src=\"http://www.marekrei.com/blog/wp-content/themes/blaskan/js/libs/respond.min.js\"></script>\r",
      "<![endif]-->\r",
      "<script type=\"text/javascript\" src=\"http://www.marekrei.com/blog/wp-content/plugins/akismet/_inc/form.js?ver=3.1.5\"></script>\n",
      "<script type=\"text/javascript\" src=\"http://www.marekrei.com/blog/wp-includes/js/comment-reply.min.js?ver=4.3.1\"></script>\n",
      "<script type=\"text/javascript\" src=\"//cdn.mathjax.org/mathjax/latest/MathJax.js?config=default&amp;ver=1.2.1\"></script>\n",
      "</body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "result = etree.tostring(ws.getroot(), pretty_print=False, method=\"html\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
